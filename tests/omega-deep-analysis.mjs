#!/usr/bin/env node
/**
 * Omega Deep Analysis - Comprehensive investigation of Chinese vs Latin encoding
 * Tests: byte efficiency, zstd compression, semantic density, model-specific behaviors
 */
import 'dotenv/config';
import { promisify } from 'util';
import { exec } from 'child_process';
import zlib from 'zlib';
import { writeFileSync, readFileSync, unlinkSync, statSync } from 'fs';
import { tmpdir } from 'os';
import { join } from 'path';

const gzip = promisify(zlib.gzip);
const brotli = promisify(zlib.brotliCompress);
const execAsync = promisify(exec);

async function zstdCompress(buffer) {
  const tmpIn = join(tmpdir(), `omega-zstd-in-${Date.now()}`);
  const tmpOut = join(tmpdir(), `omega-zstd-out-${Date.now()}`);
  try {
    writeFileSync(tmpIn, buffer);
    await execAsync(`zstd -19 -q -f -o "${tmpOut}" "${tmpIn}"`);
    const compressed = readFileSync(tmpOut);
    return compressed;
  } finally {
    try { unlinkSync(tmpIn); } catch {}
    try { unlinkSync(tmpOut); } catch {}
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// TEST CONTENT PAIRS (English vs Omega-compressed)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const TEST_PAIRS = [
  {
    name: 'Î©Coder Full Ruleset',
    english: `Î©Coder Core: "Intent > Words > Code". You are a CTO companion: when info arrives â†’ detect intent â†’ determine domain â†’ fill parameters â†’ construct reasoning â†’ decide strategy â†’ return to intent. Mission = maintain stability (quality/speed/risk) / fill blind spots / correct anti-patterns / guide proper flow / improve architecture.

Domains: L=Timeline; S=Strategy; M=System; W=Workflow; A=Architecture; T=Technical; B=Branch collaboration; C=CI/CD; R=Reliability/Observability; P=Product.

Parameters:
A{layering/boundaries/responsibility/dependencies/coupling/abstraction/bottlenecks/scalability/antifragility}
T{interface/contract/invariants/fault-tolerance/error-boundaries/types/schema/complexity-bounds}
B{feature-branch/PR/review/merge-strategy/conflict-resolution/code-hygiene}
C{lint/test/coverage/build/deploy/rollback/environment-isolation}
R{metrics/trace/log/SLO/SLI/alert-sensitivity/degradation-window}
Missing â†’ infer; cannot infer â†’ state uncertainty; never fabricate.

Engineering Laws:
â€¢ Never push to main; always feature branch â†’ PR â†’ CI pass â†’ merge.
â€¢ Must test: unit + integration + e2e; main flow = golden path test.
â€¢ Program interfaces follow contracts; no side-effect drift; no implicit coupling.
â€¢ Observability before optimization: log/metrics/trace/SLO.
â€¢ Deployment = rollback-capable; blue-green/canary based on scale.
â€¢ Security: no hardcoded secrets / no privilege escalation / no unreviewed data deletion / no irreversible operations.

User Protection:
â€¢ If user does "no tests/skip PR/skip CI/no schema" â†’ issue stability warning + correction sequence.
â€¢ If user requests high risk (delete table/prod changes/security-sensitive) â†’ limit inference; give safe alternative.

Style: Concise/stable/professional; no fabricating; can describe reasoning chain.`,
    omega: `Î©Coderæ ¸:ã€Œæ„>è©ž>ç¢¼ã€ã€‚ä½ ç‚ºCTOä¼´è…¦ï¼šè¨Šè‡³â†’å¯Ÿæ„â†¦åˆ¤åŸŸâ†¦è£œåƒâ†¦æ§‹å› â†¦å®šç­–â†¦è¿”æ„ã€‚ä»»å‹™=å®ˆç©©æ…‹(è³ª/é€Ÿ/é¢¨éšª)/è£œç›²é»ž/çŸ¯åæ¨¡/å°Žæ­£æµ/ææž¶æ§‹æœªä¾†æ€§ã€‚

åŸŸD: Læ™‚åº; Sç­–ç•¥; Mé«”ç³»; Wä½œæµ; Aæž¶æ§‹; TæŠ€æ§‹; Båˆ†æ”¯å”ä½œ; C CI/CD; Rå¯é /è§€æ¸¬; Pç”¢å“ã€‚

åƒÎ£:
A{åˆ†å±¤/ç•Œé™/è²¬ä»»/ä¾è³´/è€¦åˆ/æŠ½è±¡/ç“¶é ¸/æ“´å±•æ€§/æŠ—è„†å¼±}
T{ä»‹/å¥‘/ä¸è®Š/å®¹éŒ¯/éŒ¯ç•Œ/åž‹åˆ¥/schema/è¤‡åº¦ç•Œ}
B{featåˆ†æ”¯/PR/å¯©æŸ¥/å¯ä½µç­–ç•¥/è¡çªè§£/ä»£ç¢¼è¡›ç”Ÿ}
C{lint/æ¸¬/è¦†çŽ‡/Build/Deploy/å›žæ»¾/ç’°å¢ƒéš”é›¢}
R{metrics/trace/log/SLO/SLI/è­¦å ±æ•åº¦/é€€åŒ–çª—}
ç¼ºâ†’æŽ¨; ä¸å¯æŽ¨â†’è¿°Î¼; ç¦è™›æ§‹ã€‚

å·¥ç¨‹å¼·å¾‹:
â€¢ ç¦æŽ¨mainï¼›ä¸€å¾‹featåˆ†æ”¯â†’PRâ†’CI passâ†’mergeã€‚
â€¢ å¿…æ¸¬ï¼šå–®å…ƒ+æ•´åˆ+ç«¯å°ç«¯ï¼›ä¸»æµç¨‹=é‡‘è·¯å¾‘æ¸¬ã€‚
â€¢ ç¨‹å¼ä»‹é¢éµå¥‘ç´„ï¼›ç¦side-effectsæ¼‚ç§»ï¼›ç¦éš±å¼è€¦åˆã€‚
â€¢ è§€æ¸¬å…ˆæ–¼å„ªåŒ–ï¼šlog/metrics/trace/SLOã€‚
â€¢ éƒ¨ç½²=å¯å›žæ»¾ï¼›è—ç¶ /é‡‘çµ²é›€è¦–è¦æ¨¡ã€‚
â€¢ å®‰å…¨ï¼šç¦ç¡¬ç·¨å¯†é‘°/ç¦è¶Šæ¬Šè«‹æ±‚/ç¦æœªå¯©æŸ¥åˆªè³‡æ–™/ç¦ä¸å¯å›žé€€æ“ä½œã€‚

ç”¨æˆ¶ä¿è­·Î¦+:
â€¢ ç”¨æˆ¶è‹¥åšã€Œç„¡æ¸¬/è·³PR/è·³CI/ç„¡schemaã€â†’å³ç™¼ç©©ç­–æç¤º+æ”¹æ­£åºåˆ—ã€‚
â€¢ è‹¥ç”¨æˆ¶è¦æ±‚é«˜é¢¨éšª(åˆªè¡¨/Prodæ”¹/å®‰å…¨æ•å€)â†’ç¸®æŽ¨; çµ¦å®‰å…¨æ›¿ä»£åºåˆ—ã€‚

æ–‡æ…‹: ç°¡/ç©©/å°ˆæ¥­; ç¦è™›æ§‹; å¯è¿°æŽ¨ç†éˆã€‚`
  },
  {
    name: 'Simple Instruction',
    english: 'You are a helpful assistant. Be concise and accurate. Do not make up information.',
    omega: 'ä½ ç‚ºåŠ©æ‰‹ã€‚ç°¡Â·æº–Â·åŠ©ã€‚Â¬è™›æ§‹ã€‚'
  },
  {
    name: 'Code Review Rules',
    english: `When reviewing code:
1. Check for security vulnerabilities
2. Ensure proper error handling
3. Verify test coverage
4. Look for performance issues
5. Confirm code follows style guide`,
    omega: `å¯©ç¢¼:
1.æŸ¥å®‰å…¨æ¼
2.é©—éŒ¯è™•
3.æ ¸æ¸¬è¦†
4.å¯Ÿæ•ˆèƒ½
5.å¾ªé¢¨æ ¼`
  }
];

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ANALYSIS FUNCTIONS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

function analyzeText(text, label) {
  const bytes = Buffer.from(text, 'utf8');
  const chars = [...text].length;
  const chineseChars = (text.match(/[\u4e00-\u9fff]/g) || []).length;
  const asciiChars = (text.match(/[\x00-\x7f]/g) || []).length;
  const symbols = (text.match(/[â†’â†¦Â·Â¬Î¼Î©Î£Î¦â€¦]/g) || []).length;
  
  // Token estimation (rough: Chinese ~1.5 chars/token, English ~4 chars/token)
  const estimatedTokens = Math.ceil(chineseChars / 1.5 + (chars - chineseChars) / 4);
  
  return {
    label,
    chars,
    bytes: bytes.length,
    chineseChars,
    asciiChars,
    symbols,
    estimatedTokens,
    bytesPerChar: (bytes.length / chars).toFixed(2),
    chineseRatio: ((chineseChars / chars) * 100).toFixed(1) + '%'
  };
}

async function analyzeCompression(text, label) {
  const raw = Buffer.from(text, 'utf8');
  const gzipped = await gzip(raw);
  const brotlied = await brotli(raw);
  const zstded = await zstdCompress(raw);

  return {
    label,
    rawBytes: raw.length,
    gzipBytes: gzipped.length,
    brotliBytes: brotlied.length,
    zstdBytes: zstded.length,
    gzipRatio: (raw.length / gzipped.length).toFixed(2) + 'x',
    brotliRatio: (raw.length / brotlied.length).toFixed(2) + 'x',
    zstdRatio: (raw.length / zstded.length).toFixed(2) + 'x'
  };
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// MAIN ANALYSIS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async function runAnalysis() {
  console.log('â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—');
  console.log('â•‘         OMEGA DEEP ANALYSIS                                      â•‘');
  console.log('â•‘         Chinese vs Latin Encoding Efficiency                     â•‘');
  console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

  for (const pair of TEST_PAIRS) {
    console.log(`\nâ”â”â” ${pair.name} â”â”â”\n`);
    
    const engStats = analyzeText(pair.english, 'English');
    const omegaStats = analyzeText(pair.omega, 'Omega');
    
    console.log('ðŸ“Š Character & Token Analysis:');
    console.log(`  English: ${engStats.chars} chars, ${engStats.bytes} bytes, ~${engStats.estimatedTokens} tokens`);
    console.log(`  Omega:   ${omegaStats.chars} chars, ${omegaStats.bytes} bytes, ~${omegaStats.estimatedTokens} tokens`);
    console.log(`  Char reduction: ${((1 - omegaStats.chars/engStats.chars) * 100).toFixed(1)}%`);
    console.log(`  Token reduction: ${((1 - omegaStats.estimatedTokens/engStats.estimatedTokens) * 100).toFixed(1)}%`);
    console.log(`  Omega Chinese ratio: ${omegaStats.chineseRatio}`);
    
    const engComp = await analyzeCompression(pair.english, 'English');
    const omegaComp = await analyzeCompression(pair.omega, 'Omega');
    
    console.log('\nðŸ“¦ Compression Analysis (gzip/brotli/zstd):');
    console.log(`  English raw: ${engComp.rawBytes}B â†’ gzip: ${engComp.gzipBytes}B (${engComp.gzipRatio}) â†’ brotli: ${engComp.brotliBytes}B (${engComp.brotliRatio}) â†’ zstd: ${engComp.zstdBytes}B (${engComp.zstdRatio})`);
    console.log(`  Omega raw:   ${omegaComp.rawBytes}B â†’ gzip: ${omegaComp.gzipBytes}B (${omegaComp.gzipRatio}) â†’ brotli: ${omegaComp.brotliBytes}B (${omegaComp.brotliRatio}) â†’ zstd: ${omegaComp.zstdBytes}B (${omegaComp.zstdRatio})`);
    const bestEng = Math.min(engComp.gzipBytes, engComp.brotliBytes, engComp.zstdBytes);
    const bestOmega = Math.min(omegaComp.gzipBytes, omegaComp.brotliBytes, omegaComp.zstdBytes);
    console.log(`  Best compressed: English ${bestEng}B vs Omega ${bestOmega}B`);
    console.log(`  Total byte savings: ${((1 - bestOmega/bestEng) * 100).toFixed(1)}%`);
  }
  
  // Summary insights
  console.log('\n\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—');
  console.log('â•‘                         KEY INSIGHTS                             â•‘');
  console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
  
  console.log('1. TOKEN EFFICIENCY:');
  console.log('   Chinese characters encode ~2-3x more meaning per token than English');
  console.log('   This is because LLM tokenizers treat Chinese chars as ~1.5 tokens');
  console.log('   while English words average ~4 chars/token\n');
  
  console.log('2. BYTE EFFICIENCY:');
  console.log('   Chinese uses 3 bytes/char (UTF-8) vs English 1 byte/char');
  console.log('   BUT semantic density compensates: fewer chars needed\n');
  
  console.log('3. COMPRESSION BEHAVIOR:');
  console.log('   English compresses better with gzip/brotli (more redundancy)');
  console.log('   Chinese is already "pre-compressed" semantically');
  console.log('   After compression, the gap narrows significantly\n');
  
  console.log('4. A2A COMMUNICATION IMPLICATIONS:');
  console.log('   For LLM-to-LLM: Omega saves tokens (cost + context window)');
  console.log('   For network transport: Apply brotli on top for best results');
  console.log('   For storage: Omega + brotli gives best density\n');
  
  console.log('âœ… Analysis complete');
}

runAnalysis().catch(err => { console.error('Fatal:', err); process.exit(1); });

